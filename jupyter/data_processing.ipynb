{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be5be3fc",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cb1e6e",
   "metadata": {},
   "source": [
    "## Importation of libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87432c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/trodriten/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/trodriten/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/trodriten/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/trodriten/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# data_management\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chardet\n",
    "import re, unicodedata\n",
    "from collections import Counter\n",
    "\n",
    "# NLTK resources\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# NLP\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Split of data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Classes Balancing\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9f963d",
   "metadata": {},
   "source": [
    "## Upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e54096bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'utf-8'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../data/Resume.csv'\n",
    "with open(file_path, 'rb') as f:\n",
    "    result = chardet.detect(f.read(100000))\n",
    "encoding = result['encoding']\n",
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94943e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>Resume_html</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16852973</td>\n",
       "      <td>HR ADMINISTRATOR/MARKETING ASSOCIATE\\...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22323967</td>\n",
       "      <td>HR SPECIALIST, US HR OPERATIONS      ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33176873</td>\n",
       "      <td>HR DIRECTOR       Summary      Over 2...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27018550</td>\n",
       "      <td>HR SPECIALIST       Summary    Dedica...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17812897</td>\n",
       "      <td>HR MANAGER         Skill Highlights  ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                         Resume_str  \\\n",
       "0  16852973           HR ADMINISTRATOR/MARKETING ASSOCIATE\\...   \n",
       "1  22323967           HR SPECIALIST, US HR OPERATIONS      ...   \n",
       "2  33176873           HR DIRECTOR       Summary      Over 2...   \n",
       "3  27018550           HR SPECIALIST       Summary    Dedica...   \n",
       "4  17812897           HR MANAGER         Skill Highlights  ...   \n",
       "\n",
       "                                         Resume_html Category  \n",
       "0  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "1  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "2  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "3  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "4  <div class=\"fontsize fontface vmargins hmargin...       HR  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(file_path, encoding=encoding, engine='python')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0868428b",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73fd7c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word is not None:\n",
    "          new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "          new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "      n1word = word.lower()\n",
    "      new_words.append(n1word)\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word is not None:\n",
    "            new_word = re.sub(r'[^\\w\\s\\+\\#\\.\\-\\/&]', '', word)\n",
    "            if new_word != '':\n",
    "                new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    stop_words = set(stopwords.words('spanish')) | set(stopwords.words('english'))\n",
    "    new_words = [word for word in words if word not in stop_words]\n",
    "    return new_words\n",
    "\n",
    "def preprocessing(words):\n",
    "    words = remove_punctuation(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_non_ascii(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words\n",
    "\n",
    "def preprocess_text(s):\n",
    "    if not isinstance(s, str):\n",
    "        s = \"\"\n",
    "    tokens = word_tokenize(s)      \n",
    "    tokens = preprocessing(tokens)\n",
    "    return \" \".join(tokens) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edf900f",
   "metadata": {},
   "source": [
    "## Columns selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a26f9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                HR ADMINISTRATOR/MARKETING ASSOCIATE\\...\n",
       "1                HR SPECIALIST, US HR OPERATIONS      ...\n",
       "2                HR DIRECTOR       Summary      Over 2...\n",
       "3                HR SPECIALIST       Summary    Dedica...\n",
       "4                HR MANAGER         Skill Highlights  ...\n",
       "                              ...                        \n",
       "2479             RANK: SGT/E-5 NON- COMMISSIONED OFFIC...\n",
       "2480             GOVERNMENT RELATIONS, COMMUNICATIONS ...\n",
       "2481             GEEK SQUAD AGENT         Professional...\n",
       "2482             PROGRAM DIRECTOR / OFFICE MANAGER    ...\n",
       "2483             STOREKEEPER II       Professional Sum...\n",
       "Name: Resume_str, Length: 2484, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw = data['Resume_str']\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10f3864e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             HR\n",
       "1             HR\n",
       "2             HR\n",
       "3             HR\n",
       "4             HR\n",
       "          ...   \n",
       "2479    AVIATION\n",
       "2480    AVIATION\n",
       "2481    AVIATION\n",
       "2482    AVIATION\n",
       "2483    AVIATION\n",
       "Name: Category, Length: 2484, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['Category']\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2e9cf0",
   "metadata": {},
   "source": [
    "## Split of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fc7aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X_raw, y, stratify=y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c13a119c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1987,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2894f6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(497,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5eab5496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1987,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52734f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(497,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7e6d95",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50b25eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean = X_train_raw.apply(preprocess_text)\n",
    "X_test_clean = X_test_raw.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bb9e00",
   "metadata": {},
   "source": [
    "## Training data balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8c10409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap_boost_resample(X_text, y, under_cap=100, target_min=80, random_state=42):\n",
    "    cnt = Counter(y)\n",
    "    under_strategy = {c: under_cap for c, n in cnt.items() if n > under_cap}\n",
    "    over_strategy  = {c: target_min for c, n in cnt.items() if n < target_min}\n",
    "\n",
    "    X_arr = np.array(list(X_text), dtype=object).reshape(-1, 1)\n",
    "\n",
    "    if under_strategy:\n",
    "        rus = RandomUnderSampler(sampling_strategy=under_strategy, random_state=random_state)\n",
    "        X_u, y_u = rus.fit_resample(X_arr, y)\n",
    "    else:\n",
    "        X_u, y_u = X_arr, y\n",
    "\n",
    "    cnt_u = Counter(y_u)\n",
    "    over_strategy = {c: target_min for c, n in cnt_u.items() if n < target_min}\n",
    "    if over_strategy:\n",
    "        ros = RandomOverSampler(sampling_strategy=over_strategy, random_state=random_state)\n",
    "        X_b, y_b = ros.fit_resample(X_u, y_u)\n",
    "    else:\n",
    "        X_b, y_b = X_u, y_u\n",
    "\n",
    "    X_b = X_b.ravel().tolist()\n",
    "    return X_b, y_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42d1cd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bal, y_train_bal = cap_boost_resample(X_train_clean, y_train, under_cap=100, target_min=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5430aa8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2135"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "330aac5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2135"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train_bal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a39e29a",
   "metadata": {},
   "source": [
    "## Data saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c7f0bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_bal = pd.DataFrame({\n",
    "    \"text\": pd.Series(X_train_bal, dtype=\"object\"),\n",
    "    \"label\": pd.Series(y_train_bal, dtype=\"object\")\n",
    "})\n",
    "df_train_bal.to_csv(\"../data/train_clean_balanced.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01cfe6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_clean = pd.DataFrame({\n",
    "    \"text\": pd.Series(X_test_clean, dtype=\"object\"),\n",
    "    \"label\": pd.Series(y_test, dtype=\"object\")\n",
    "})\n",
    "df_test_clean.to_csv(\"../data/test_clean.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
